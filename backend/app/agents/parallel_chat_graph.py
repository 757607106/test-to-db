"""
å¹¶è¡Œæ™ºèƒ½SQLä»£ç†å›¾ - ä¼˜åŒ–ç‰ˆ
é›†æˆ MemorySaver å®žçŽ°çŠ¶æ€æŒä¹…åŒ–
ä½¿ç”¨ Refactored SQLGeneratorAgent
"""
from typing import Dict, Any, List, Annotated, Optional
import operator
from typing_extensions import TypedDict

from langgraph.graph import StateGraph, START, END
from langgraph.types import Send
from langgraph.checkpoint.memory import MemorySaver

from app.core.state import SQLMessageState
from app.agents.agents.supervisor_agent import create_intelligent_sql_supervisor
from app.agents.agents.sql_generator_agent import sql_generator_agent

# å¹¶è¡Œå·¥ä½œæµçŠ¶æ€
class ParallelSQLState(TypedDict):
    """å¹¶è¡ŒSQLå¤„ç†çŠ¶æ€"""
    # åŸºç¡€æ¶ˆæ¯çŠ¶æ€
    messages: Annotated[List[Dict[str, Any]], operator.add]
    connection_id: Annotated[int, lambda x, y: y or x]
    current_stage: Annotated[str, lambda x, y: y or x]
    retry_count: Annotated[int, lambda x, y: y or x]
    max_retries: Annotated[int, lambda x, y: y or x]
    error_history: Annotated[List[Dict[str, Any]], operator.add]
    
    # ä»£ç†æ¶ˆæ¯
    agent_messages: Annotated[Dict[str, Any], lambda x, y: {**x, **y} if x and y else y or x]
    
    # å¹¶è¡Œå¤„ç†ç‰¹æœ‰å­—æ®µ
    parallel_validation_results: Annotated[List[Dict[str, Any]], operator.add]
    parallel_execution_results: Annotated[List[Dict[str, Any]], operator.add]
    
    # å¤„ç†ç»“æžœ
    schema_info: Annotated[Dict[str, Any], lambda x, y: y or x]
    sample_retrieval_result: Annotated[Dict[str, Any], lambda x, y: y or x] # æ–°å¢ž
    generated_sql: Annotated[str, lambda x, y: y or x]
    validation_summary: Annotated[Dict[str, Any], lambda x, y: y or x]
    execution_result: Annotated[Dict[str, Any], lambda x, y: y or x]
    chart_result: Annotated[Dict[str, Any], lambda x, y: y or x]
    final_result: Annotated[Dict[str, Any], lambda x, y: y or x]


class ParallelIntelligentSQLGraph:
    """å¹¶è¡Œæ™ºèƒ½SQLä»£ç†å›¾"""
    
    def __init__(self):
        self.supervisor_agent = create_intelligent_sql_supervisor()
        self._worker_agents = self.supervisor_agent.worker_agents
        
        # åˆå§‹åŒ– Checkpointer
        self.checkpointer = MemorySaver()
        
        # æž„å»ºå·¥ä½œæµå›¾
        self.graph = self._build_parallel_graph()
    
    def _build_parallel_graph(self) -> StateGraph:
        workflow = StateGraph(ParallelSQLState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("initialize", self._initialize_node)
        workflow.add_node("schema_analysis", self._schema_analysis_node)
        workflow.add_node("sql_generation", self._sql_generation_node)
        
        # å¹¶è¡ŒéªŒè¯
        workflow.add_node("parallel_validation_orchestrator", self._parallel_validation_orchestrator)
        workflow.add_node("validation_worker", self._validation_worker_node)
        workflow.add_node("validation_synthesizer", self._validation_synthesizer_node)
        
        # å¹¶è¡Œæ‰§è¡Œ
        workflow.add_node("parallel_execution_orchestrator", self._parallel_execution_orchestrator)
        workflow.add_node("execution_worker", self._execution_worker_node)
        workflow.add_node("execution_synthesizer", self._execution_synthesizer_node)
        
        # é”™è¯¯å¤„ç†
        workflow.add_node("error_recovery", self._error_recovery_node)
        workflow.add_node("finalize", self._finalize_node)
        
        # è¾¹å®šä¹‰
        workflow.add_edge(START, "initialize")
        workflow.add_edge("initialize", "schema_analysis")
        workflow.add_edge("schema_analysis", "sql_generation")
        
        workflow.add_edge("sql_generation", "parallel_validation_orchestrator")
        workflow.add_conditional_edges(
            "parallel_validation_orchestrator",
            self._assign_validation_workers,
            ["validation_worker"]
        )
        workflow.add_edge("validation_worker", "validation_synthesizer")
        
        workflow.add_conditional_edges(
            "validation_synthesizer",
            self._route_after_validation,
            {"execute": "parallel_execution_orchestrator", "error": "error_recovery"}
        )
        
        workflow.add_conditional_edges(
            "parallel_execution_orchestrator",
            self._assign_execution_workers,
            ["execution_worker"]
        )
        workflow.add_edge("execution_worker", "execution_synthesizer")
        workflow.add_edge("execution_synthesizer", "finalize")
        workflow.add_edge("finalize", END)
        
        workflow.add_conditional_edges(
            "error_recovery",
            self._route_after_error_recovery,
            {
                "retry_schema": "schema_analysis",
                "retry_sql": "sql_generation",
                "retry_validation": "parallel_validation_orchestrator",
                "failed": "finalize"
            }
        )
        
        return workflow.compile(checkpointer=self.checkpointer)
    
    def _initialize_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        """åˆå§‹åŒ–èŠ‚ç‚¹"""
        # å¦‚æžœæ˜¯æ–°çš„ä¼šè¯ï¼Œé‡ç½®çŠ¶æ€ï¼›å¦‚æžœæ˜¯ç»§ç»­å¯¹è¯ï¼Œä¿ç•™ messages ä½†é‡ç½®å½“å‰è½®æ¬¡çš„ä¸´æ—¶çŠ¶æ€
        # è¿™é‡Œä¸ºäº†ç®€åŒ–ï¼Œå‡è®¾æ¯æ¬¡è°ƒç”¨éƒ½æ˜¯æ–°çš„ä¸€è½®å¤„ç†ï¼Œä½†åŽ†å² messages ç”± checkpointer ç®¡ç†
        return {
            "parallel_validation_results": [],
            "parallel_execution_results": [],
            # "schema_info": {}, # ä¿ç•™ Schema å¯èƒ½æœ‰åŠ©äºŽå¤šè½®å¯¹è¯
            "generated_sql": "",
            "validation_summary": {},
            "execution_result": {},
            "chart_result": {},
            "final_result": {},
            "current_stage": "schema_analysis"
        }
    
    async def _schema_analysis_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        """Schemaåˆ†æžèŠ‚ç‚¹"""
        try:
            print(f"ðŸ” å¼€å§‹Schemaåˆ†æž...")
            # æž„å»ºå…¼å®¹çš„çŠ¶æ€å¯¹è±¡
            message_state = SQLMessageState(
                messages=state["messages"],
                connection_id=state["connection_id"],
                current_stage="schema_analysis",
                retry_count=state.get("retry_count", 0),
                max_retries=state.get("max_retries", 3),
                error_history=state.get("error_history", []),
                agent_messages=state.get("agent_messages", {})
            )
            
            schema_agent = self._worker_agents[0]
            result = await schema_agent.ainvoke(message_state)
            
            # å…¼å®¹æ—§çš„ extraction é€»è¾‘ï¼Œç›´åˆ° schema_agent ä¹Ÿé‡æž„
            schema_info = self._extract_schema_info_from_result(result)
            
            return {
                "schema_info": schema_info,
                "current_stage": "sql_generation",
                "agent_messages": {"schema_agent": result}
            }
        except Exception as e:
            print(f"âŒ Schemaåˆ†æžå¤±è´¥: {str(e)}")
            return {
                "error_history": [{"stage": "schema_analysis", "error": str(e)}],
                "current_stage": "error_recovery"
            }

    async def _sql_generation_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        """SQLç”ŸæˆèŠ‚ç‚¹ - ä½¿ç”¨æ–°çš„ SQLGeneratorAgent"""
        try:
            print(f"ðŸ” å¼€å§‹SQLç”Ÿæˆ (New Architecture)...")
            
            # ç›´æŽ¥è°ƒç”¨æ–°çš„ process æ–¹æ³•ï¼Œå®ƒè¿”å›žåŒ…å« generated_sql çš„ dict
            result = await sql_generator_agent.process(state)
            
            if result.get("current_stage") == "error_recovery":
                 return result

            return {
                **result, # åŒ…å« generated_sql, agent_messages
                "current_stage": "parallel_validation"
            }
            
        except Exception as e:
            print(f"âŒ SQLç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "error_history": [{"stage": "sql_generation", "error": str(e)}],
                "current_stage": "error_recovery"
            }

    # ... éªŒè¯å’Œæ‰§è¡ŒèŠ‚ç‚¹ä¿æŒå¤§ä½“ä¸å˜ï¼Œä½†è¦ç¡®ä¿çŠ¶æ€ä¼ é€’æ­£ç¡® ...
    # ä¸ºèŠ‚çœç¯‡å¹…ï¼Œå¤ç”¨åŽŸæœ‰é€»è¾‘ä½†ç®€åŒ–ä¸å¿…è¦çš„æ‰“å°å’Œæå–

    def _parallel_validation_orchestrator(self, state: ParallelSQLState) -> Dict[str, Any]:
        return {"current_stage": "parallel_validation"}

    def _assign_validation_workers(self, state: ParallelSQLState):
        sql_query = state.get("generated_sql")
        if not sql_query:
            return []
        
        # æš‚æ—¶åªåˆ†é…ä¸€ä¸ªéªŒè¯ä»»åŠ¡ï¼ŒåŽç»­å¯æ‰©å±•
        validation_tasks = [{"agent_index": 2, "agent_name": "sql_validator", "task_type": "validation"}]
        
        return [
            Send("validation_worker", {
                "sql_query": sql_query,
                "schema_info": state.get("schema_info", {}),
                "messages": state["messages"],
                "connection_id": state["connection_id"],
                "agent_messages": state.get("agent_messages", {}),
                "task": task
            })
            for task in validation_tasks
        ]

    async def _validation_worker_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        try:
            task = state["task"]
            agent_index = task["agent_index"]
            agent = self._worker_agents[agent_index]
            
            message_state = SQLMessageState(
                messages=state["messages"],
                connection_id=state["connection_id"],
                current_stage="sql_validation",
                retry_count=0, max_retries=3, error_history=[],
                agent_messages=state.get("agent_messages", {})
            )
            message_state["schema_info"] = state.get("schema_info", {})
            message_state["generated_sql"] = state["sql_query"]
            
            result = await agent.ainvoke(message_state)
            
            return {
                "parallel_validation_results": [{
                    "agent_name": task["agent_name"],
                    "task_type": task["task_type"],
                    "result": result,
                    "success": True
                }]
            }
        except Exception as e:
             return {
                "parallel_validation_results": [{
                    "agent_name": task["agent_name"],
                    "success": False,
                    "result": {"error": str(e)}
                }]
            }

    def _validation_synthesizer_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        results = state.get("parallel_validation_results", [])
        overall_valid = all(r.get("success") for r in results) # ç®€åŒ–é€»è¾‘
        # å®žé™…é€»è¾‘åº”æ£€æŸ¥ result å†…éƒ¨çš„ valid å­—æ®µ
        
        return {
            "validation_summary": {"overall_valid": overall_valid, "count": len(results)},
            "current_stage": "parallel_execution" if overall_valid else "error_recovery"
        }

    def _route_after_validation(self, state: ParallelSQLState) -> str:
        return "execute" if state.get("validation_summary", {}).get("overall_valid", False) else "error"

    def _parallel_execution_orchestrator(self, state: ParallelSQLState) -> Dict[str, Any]:
        return {"current_stage": "parallel_execution"}

    def _assign_execution_workers(self, state: ParallelSQLState):
        user_query = ""
        # å¥å£®åœ°èŽ·å– user_query
        if state["messages"]:
             last_msg = state["messages"][-1]
             if isinstance(last_msg, dict):
                 user_query = last_msg.get("content", "").lower()
             elif hasattr(last_msg, "content"):
                 user_query = last_msg.content.lower()

        needs_chart = any(k in user_query for k in ["å›¾", "chart", "trend", "plot"])
        
        execution_tasks = [{"agent_index": 3, "agent_name": "sql_executor", "task_type": "execution"}]
        if needs_chart:
            execution_tasks.append({"agent_index": 5, "agent_name": "chart_generator", "task_type": "chart_generation"})
            
        return [
            Send("execution_worker", {
                "sql_query": state.get("generated_sql"),
                "schema_info": state.get("schema_info", {}),
                "messages": state["messages"],
                "connection_id": state["connection_id"],
                "agent_messages": state.get("agent_messages", {}),
                "validation_summary": state.get("validation_summary", {}),
                "task": task
            })
            for task in execution_tasks
        ]

    async def _execution_worker_node(self, state: Dict[str, Any]) -> Dict[str, Any]:
        try:
            task = state["task"]
            agent = self._worker_agents[task["agent_index"]]
            
            message_state = SQLMessageState(
                messages=state["messages"],
                connection_id=state["connection_id"],
                current_stage=task["task_type"],
                retry_count=0, max_retries=3, error_history=[],
                agent_messages=state.get("agent_messages", {})
            )
            message_state["schema_info"] = state.get("schema_info", {})
            message_state["generated_sql"] = state["sql_query"]
            message_state["validation_summary"] = state.get("validation_summary", {})
            
            result = await agent.ainvoke(message_state)
            
            return {
                "parallel_execution_results": [{
                    "agent_name": task["agent_name"],
                    "task_type": task["task_type"],
                    "result": result,
                    "success": True
                }]
            }
        except Exception as e:
            return {
                "parallel_execution_results": [{
                    "agent_name": task["agent_name"],
                    "success": False,
                    "result": {"error": str(e)}
                }]
            }

    def _execution_synthesizer_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        results = state.get("parallel_execution_results", [])
        exec_res = {}
        chart_res = {}
        for r in results:
            if r["task_type"] == "execution":
                exec_res = r.get("result", {})
            elif r["task_type"] == "chart_generation":
                chart_res = r.get("result", {})
                
        return {
            "execution_result": exec_res,
            "chart_result": chart_res,
            "current_stage": "finalize"
        }

    async def _error_recovery_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        # ç®€åŒ–ï¼šç›´æŽ¥å¢žåŠ é‡è¯•è®¡æ•°ï¼Œè¿”å›ž schema_analysis
        return {
            "retry_count": state.get("retry_count", 0) + 1,
            "current_stage": "schema_analysis"
        }

    def _route_after_error_recovery(self, state: ParallelSQLState) -> str:
        if state.get("retry_count", 0) >= state.get("max_retries", 3):
            return "failed"
        return "retry_schema"

    def _finalize_node(self, state: ParallelSQLState) -> Dict[str, Any]:
        final_result = {
            "success": state.get("current_stage") != "failed",
            "generated_sql": state.get("generated_sql"),
            "execution_result": state.get("execution_result"),
            "chart_result": state.get("chart_result")
        }
        return {"final_result": final_result, "current_stage": "completed"}

    # è¾…åŠ©æ–¹æ³• (ä¿ç•™ schema extraction å› ä¸º schema_agent æœªé‡æž„)
    def _extract_schema_info_from_result(self, result: Any) -> Dict[str, Any]:
        if isinstance(result, dict) and "schema" in result: return result["schema"]
        if hasattr(result, "content"): return {"schema_context": result.content}
        return {"extracted": False}

    async def process_query(self, query: str, connection_id: int = 15, thread_id: str = "default") -> Dict[str, Any]:
        """å¤„ç†æŸ¥è¯¢ï¼Œæ”¯æŒ thread_id æŒä¹…åŒ–"""
        config = {"configurable": {"thread_id": thread_id}}
        
        # åˆå§‹çŠ¶æ€åªåŒ…å«æ–°æ¶ˆæ¯ï¼ŒLangGraph ä¼šè‡ªåŠ¨åˆå¹¶åŽ†å²
        initial_state = {
            "messages": [{"role": "user", "content": query}],
            "connection_id": connection_id,
            "current_stage": "initialize"
        }
        
        try:
            result = await self.graph.ainvoke(initial_state, config=config)
            return {
                "success": True,
                "result": result.get("final_result"),
                "thread_id": thread_id
            }
        except Exception as e:
            return {"success": False, "error": str(e)}

# å…¨å±€å®žä¾‹å·¥åŽ‚
def create_parallel_intelligent_sql_graph() -> ParallelIntelligentSQLGraph:
    return ParallelIntelligentSQLGraph()

_global_graph = None
def get_global_parallel_graph():
    global _global_graph
    if _global_graph is None:
        _global_graph = create_parallel_intelligent_sql_graph()
    return _global_graph
