# å¼‚æ­¥ä¼˜åŒ–å®æˆ˜ç¤ºä¾‹

## 1. æµå¼å“åº”APIå®ç°

### 1.1 SSE (Server-Sent Events) æµå¼API

**åœºæ™¯**: å®æ—¶æ¨é€agentæ‰§è¡Œè¿›åº¦ï¼Œæå‡ç”¨æˆ·ä½“éªŒ

```python
# backend/app/api/api_v1/endpoints/query.py

from fastapi import APIRouter
from fastapi.responses import StreamingResponse
from sse_starlette.sse import EventSourceResponse
import json
import asyncio
from typing import AsyncGenerator

router = APIRouter()

@router.post("/chat/stream")
async def chat_query_stream(
    chat_request: schemas.ChatQueryRequest,
    db: Session = Depends(deps.get_db)
) -> EventSourceResponse:
    """
    æµå¼èŠå¤©æŸ¥è¯¢æ¥å£
    
    å®æ—¶æ¨é€:
    - èŠ‚ç‚¹æ‰§è¡Œè¿›åº¦
    - ä¸­é—´ç»“æœ
    - æœ€ç»ˆç»“æœ
    
    å‰ç«¯ä½¿ç”¨EventSourceæ¥æ”¶
    """
    
    async def event_generator() -> AsyncGenerator[dict, None]:
        """ç”ŸæˆSSEäº‹ä»¶æµ"""
        try:
            # åˆ›å»ºå›¾å®ä¾‹
            thread_id = chat_request.conversation_id or str(uuid4())
            graph = IntelligentSQLGraph()
            
            # æ„å»ºåˆå§‹çŠ¶æ€
            initial_state = SQLMessageState(
                messages=[HumanMessage(content=chat_request.natural_language_query)],
                connection_id=chat_request.connection_id,
                thread_id=thread_id,
                current_stage="schema_analysis"
            )
            
            config = {"configurable": {"thread_id": thread_id}}
            
            # æµå¼æ‰§è¡Œå›¾
            async for chunk in graph.graph.astream(
                initial_state, 
                config=config,
                stream_mode="updates"  # æ¯ä¸ªèŠ‚ç‚¹æ‰§è¡Œåæ¨é€æ›´æ–°
            ):
                for node_name, node_output in chunk.items():
                    # æ ¼å¼åŒ–èŠ‚ç‚¹è¾“å‡º
                    event_data = {
                        "type": "node_update",
                        "node": node_name,
                        "stage": node_output.get("current_stage", "processing"),
                        "timestamp": time.time()
                    }
                    
                    # æ·»åŠ èŠ‚ç‚¹ç‰¹å®šæ•°æ®
                    if node_name == "cache_check":
                        event_data["cache_hit"] = node_output.get("cache_hit", False)
                    
                    elif node_name == "clarification":
                        if node_output.get("needs_clarification"):
                            event_data["clarification_questions"] = node_output.get("clarification_questions", [])
                    
                    elif node_name == "supervisor":
                        # æå–SQLå’Œæ‰§è¡Œç»“æœ
                        if node_output.get("generated_sql"):
                            event_data["sql"] = node_output["generated_sql"]
                        if node_output.get("execution_result"):
                            exec_result = node_output["execution_result"]
                            event_data["result_preview"] = {
                                "success": exec_result.success,
                                "row_count": len(exec_result.data) if exec_result.data else 0
                            }
                    
                    # æ¨é€äº‹ä»¶
                    yield {
                        "event": "update",
                        "data": json.dumps(event_data, ensure_ascii=False)
                    }
                    
                    # å°å»¶è¿Ÿï¼Œé¿å…å‰ç«¯å¤„ç†ä¸è¿‡æ¥
                    await asyncio.sleep(0.1)
            
            # å‘é€å®Œæˆäº‹ä»¶
            yield {
                "event": "complete",
                "data": json.dumps({
                    "type": "complete",
                    "thread_id": thread_id
                })
            }
        
        except Exception as e:
            # é”™è¯¯äº‹ä»¶
            yield {
                "event": "error",
                "data": json.dumps({
                    "type": "error",
                    "error": str(e)
                })
            }
    
    return EventSourceResponse(event_generator())
```

---

### 1.2 å‰ç«¯é›†æˆ (TypeScript/React)

```typescript
// frontend/chat/src/hooks/useStreamingChat.ts

import { useEffect, useState } from 'react';

interface StreamEvent {
  type: 'node_update' | 'complete' | 'error';
  node?: string;
  stage?: string;
  cache_hit?: boolean;
  sql?: string;
  result_preview?: {
    success: boolean;
    row_count: number;
  };
  error?: string;
}

export function useStreamingChat(queryRequest: ChatQueryRequest) {
  const [events, setEvents] = useState<StreamEvent[]>([]);
  const [isStreaming, setIsStreaming] = useState(false);
  const [currentStage, setCurrentStage] = useState<string>('');

  useEffect(() => {
    if (!queryRequest.natural_language_query) return;

    setIsStreaming(true);
    setEvents([]);

    // åˆ›å»ºEventSourceè¿æ¥
    const eventSource = new EventSource('/api/query/chat/stream', {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json'
      },
      body: JSON.stringify(queryRequest)
    });

    eventSource.addEventListener('update', (e) => {
      const data: StreamEvent = JSON.parse(e.data);
      setEvents(prev => [...prev, data]);
      
      // æ›´æ–°UIçŠ¶æ€
      if (data.stage) {
        setCurrentStage(getStageLabel(data.stage));
      }
    });

    eventSource.addEventListener('complete', () => {
      setIsStreaming(false);
      eventSource.close();
    });

    eventSource.addEventListener('error', (e) => {
      console.error('Stream error:', e);
      setIsStreaming(false);
      eventSource.close();
    });

    return () => {
      eventSource.close();
    };
  }, [queryRequest]);

  return { events, isStreaming, currentStage };
}

function getStageLabel(stage: string): string {
  const labels: Record<string, string> = {
    'cache_check': 'ğŸ” æ£€æŸ¥ç¼“å­˜...',
    'schema_analysis': 'ğŸ“Š åˆ†ææ•°æ®åº“ç»“æ„...',
    'sql_generation': 'âš™ï¸ ç”ŸæˆSQLæŸ¥è¯¢...',
    'sql_execution': 'ğŸš€ æ‰§è¡ŒæŸ¥è¯¢...',
    'chart_generation': 'ğŸ“ˆ ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...',
    'completed': 'âœ… å®Œæˆ'
  };
  return labels[stage] || 'â³ å¤„ç†ä¸­...';
}
```

---

### 1.3 UIç»„ä»¶ç¤ºä¾‹

```tsx
// frontend/chat/src/components/StreamingChatInterface.tsx

export function StreamingChatInterface() {
  const [query, setQuery] = useState('');
  const { events, isStreaming, currentStage } = useStreamingChat({
    natural_language_query: query,
    connection_id: 15
  });

  return (
    <div className="streaming-chat">
      <input
        value={query}
        onChange={(e) => setQuery(e.target.value)}
        placeholder="è¯·è¾“å…¥æŸ¥è¯¢..."
      />
      
      {isStreaming && (
        <div className="progress-indicator">
          <div className="spinner"></div>
          <span>{currentStage}</span>
        </div>
      )}

      <div className="events-timeline">
        {events.map((event, idx) => (
          <EventCard key={idx} event={event} />
        ))}
      </div>
    </div>
  );
}

function EventCard({ event }: { event: StreamEvent }) {
  return (
    <div className={`event-card ${event.type}`}>
      <div className="event-header">
        <span className="node-name">{event.node}</span>
        <span className="timestamp">{new Date().toLocaleTimeString()}</span>
      </div>
      
      {event.cache_hit && (
        <div className="cache-hit">
          âš¡ ç¼“å­˜å‘½ä¸­ï¼Œå¿«é€Ÿè¿”å›ç»“æœ
        </div>
      )}
      
      {event.sql && (
        <pre className="sql-preview">
          <code>{event.sql}</code>
        </pre>
      )}
      
      {event.result_preview && (
        <div className="result-preview">
          {event.result_preview.success ? (
            `âœ… æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› ${event.result_preview.row_count} æ¡è®°å½•`
          ) : (
            `âŒ æŸ¥è¯¢å¤±è´¥`
          )}
        </div>
      )}
    </div>
  );
}
```

---

## 2. å¹¶è¡Œç¼“å­˜æ£€æŸ¥ä¼˜åŒ–

### 2.1 ä¼˜åŒ–å‰ (ä¸²è¡Œæ£€æŸ¥)

```python
# å½“å‰å®ç° - ä¸²è¡Œæ£€æŸ¥L1å’ŒL2ç¼“å­˜
async def cache_check_node(state: SQLMessageState) -> Dict[str, Any]:
    cache_service = get_cache_service()
    
    # å…ˆæ£€æŸ¥ç²¾ç¡®åŒ¹é… (L1)
    exact_hit = await cache_service.check_exact_cache(query, conn_id)
    if exact_hit:
        return format_cache_result(exact_hit)
    
    # æœªå‘½ä¸­ï¼Œå†æ£€æŸ¥è¯­ä¹‰åŒ¹é… (L2)
    semantic_hit = await cache_service.check_semantic_cache(query, conn_id)
    if semantic_hit:
        return format_cache_result(semantic_hit)
    
    return {"cache_hit": False}

# æ€§èƒ½: L1 (100ms) + L2 (300ms) = 400ms
```

---

### 2.2 ä¼˜åŒ–å (å¹¶è¡Œæ£€æŸ¥)

```python
# backend/app/agents/nodes/cache_check_node_optimized.py

import asyncio
from typing import Optional, Union

async def cache_check_node_parallel(state: SQLMessageState) -> Dict[str, Any]:
    """
    å¹¶è¡Œæ£€æŸ¥L1å’ŒL2ç¼“å­˜ï¼Œå…ˆè¿”å›çš„ç»“æœç”Ÿæ•ˆ
    
    æ€§èƒ½æå‡:
    - ä¸²è¡Œ: L1 + L2 = 100ms + 300ms = 400ms
    - å¹¶è¡Œ: max(L1, L2) = max(100ms, 300ms) = 300ms
    - æå‡: 25%
    """
    logger.info("=== å¹¶è¡Œç¼“å­˜æ£€æŸ¥ ===")
    
    cache_service = get_cache_service()
    query = extract_user_query(state.get("messages", []))
    conn_id = state.get("connection_id", 15)
    
    # åˆ›å»ºå¹¶è¡Œä»»åŠ¡
    l1_task = asyncio.create_task(
        cache_service.check_exact_cache(query, conn_id),
        name="L1_exact_cache"
    )
    
    l2_task = asyncio.create_task(
        cache_service.check_semantic_cache(query, conn_id),
        name="L2_semantic_cache"
    )
    
    # ç­‰å¾…ç¬¬ä¸€ä¸ªå®Œæˆçš„ä»»åŠ¡
    done, pending = await asyncio.wait(
        {l1_task, l2_task},
        return_when=asyncio.FIRST_COMPLETED
    )
    
    # è·å–ç¬¬ä¸€ä¸ªå®Œæˆçš„ç»“æœ
    first_result: Optional[CacheHit] = None
    for task in done:
        result = task.result()
        if result:  # å‘½ä¸­ç¼“å­˜
            first_result = result
            logger.info(f"ç¼“å­˜å‘½ä¸­: {task.get_name()}")
            break
    
    # å–æ¶ˆæœªå®Œæˆçš„ä»»åŠ¡
    for task in pending:
        task.cancel()
        try:
            await task
        except asyncio.CancelledError:
            pass
    
    if first_result:
        return {
            "cache_hit": True,
            "cache_hit_type": first_result.hit_type,
            "generated_sql": first_result.sql,
            # ...
        }
    
    # ç­‰å¾…æ‰€æœ‰ä»»åŠ¡å®Œæˆï¼Œæ£€æŸ¥æ˜¯å¦æœ‰å…¶ä»–å‘½ä¸­
    if pending:
        remaining_results = await asyncio.gather(*pending, return_exceptions=True)
        for result in remaining_results:
            if isinstance(result, CacheHit):
                return format_cache_result(result)
    
    return {"cache_hit": False}
```

---

### 2.3 é«˜çº§ä¼˜åŒ– - è¶…æ—¶å’Œé€€åŒ–

```python
async def cache_check_node_with_timeout(state: SQLMessageState) -> Dict[str, Any]:
    """
    å¸¦è¶…æ—¶çš„å¹¶è¡Œç¼“å­˜æ£€æŸ¥
    
    å¦‚æœç¼“å­˜æŸ¥è¯¢è¶…æ—¶ï¼Œç›´æ¥è·³è¿‡ç¼“å­˜ç»§ç»­æ‰§è¡Œ
    é¿å…ç¼“å­˜æœåŠ¡æ•…éšœå½±å“ä¸»æµç¨‹
    """
    try:
        # è®¾ç½®æ€»è¶…æ—¶æ—¶é—´
        return await asyncio.wait_for(
            cache_check_node_parallel(state),
            timeout=2.0  # 2ç§’è¶…æ—¶
        )
    except asyncio.TimeoutError:
        logger.warning("ç¼“å­˜æŸ¥è¯¢è¶…æ—¶ï¼Œè·³è¿‡ç¼“å­˜ç»§ç»­æ‰§è¡Œ")
        return {
            "cache_hit": False,
            "cache_timeout": True
        }
    except Exception as e:
        logger.error(f"ç¼“å­˜æŸ¥è¯¢å¼‚å¸¸: {e}")
        # é™çº§å¤„ç†ï¼Œç»§ç»­æ‰§è¡Œ
        return {
            "cache_hit": False,
            "cache_error": str(e)
        }
```

---

## 3. å¼‚æ­¥ORMè¿ç§»ç¤ºä¾‹

### 3.1 å½“å‰åŒæ­¥å®ç°

```python
# backend/app/agents/chat_graph.py (å½“å‰)

async def _load_custom_agent_node(self, state):
    """åŠ è½½è‡ªå®šä¹‰agent - ä½¿ç”¨åŒæ­¥æ•°æ®åº“"""
    from app.db.session import SessionLocal
    
    # âš ï¸ åŒæ­¥æ•°æ®åº“ä¼šè¯
    db = SessionLocal()
    try:
        # âš ï¸ åŒæ­¥æŸ¥è¯¢ - é˜»å¡äº‹ä»¶å¾ªç¯
        profile = crud_agent_profile.get(db=db, id=agent_id)
        
        if profile and not profile.is_system:
            custom_analyst = create_custom_analyst_agent(profile, db)
            # ...
    finally:
        db.close()
```

---

### 3.2 è¿ç§»åˆ°å¼‚æ­¥ORM

#### Step 1: é…ç½®å¼‚æ­¥å¼•æ“

```python
# backend/app/db/async_session.py (æ–°å¢)

from sqlalchemy.ext.asyncio import (
    AsyncSession,
    create_async_engine,
    async_sessionmaker
)
from app.core.config import settings

# åˆ›å»ºå¼‚æ­¥å¼•æ“
async_engine = create_async_engine(
    settings.SQLALCHEMY_DATABASE_URI.replace(
        "mysql://", "mysql+aiomysql://"
    ),
    echo=False,
    pool_pre_ping=True,
    pool_size=20,
    max_overflow=40
)

# å¼‚æ­¥ä¼šè¯å·¥å‚
AsyncSessionLocal = async_sessionmaker(
    async_engine,
    class_=AsyncSession,
    expire_on_commit=False
)

async def get_async_db():
    """å¼‚æ­¥æ•°æ®åº“ä¾èµ–æ³¨å…¥"""
    async with AsyncSessionLocal() as session:
        yield session
```

---

#### Step 2: æ”¹å†™CRUDæ“ä½œ

```python
# backend/app/crud/async_crud_agent_profile.py (æ–°å¢)

from sqlalchemy import select
from sqlalchemy.ext.asyncio import AsyncSession
from app.models.agent_profile import AgentProfile

class AsyncCRUDAgentProfile:
    """å¼‚æ­¥Agent Profile CRUD"""
    
    async def get(
        self, 
        db: AsyncSession, 
        id: int
    ) -> Optional[AgentProfile]:
        """å¼‚æ­¥æŸ¥è¯¢å•ä¸ªprofile"""
        result = await db.execute(
            select(AgentProfile).where(AgentProfile.id == id)
        )
        return result.scalar_one_or_none()
    
    async def get_multi(
        self,
        db: AsyncSession,
        skip: int = 0,
        limit: int = 100
    ) -> List[AgentProfile]:
        """å¼‚æ­¥æŸ¥è¯¢å¤šä¸ªprofiles"""
        result = await db.execute(
            select(AgentProfile)
            .offset(skip)
            .limit(limit)
        )
        return result.scalars().all()
    
    async def create(
        self,
        db: AsyncSession,
        obj_in: AgentProfileCreate
    ) -> AgentProfile:
        """å¼‚æ­¥åˆ›å»ºprofile"""
        db_obj = AgentProfile(**obj_in.dict())
        db.add(db_obj)
        await db.commit()
        await db.refresh(db_obj)
        return db_obj

async_agent_profile = AsyncCRUDAgentProfile()
```

---

#### Step 3: æ›´æ–°èŠ‚ç‚¹ä½¿ç”¨å¼‚æ­¥æŸ¥è¯¢

```python
# backend/app/agents/chat_graph.py (æ›´æ–°)

async def _load_custom_agent_node(self, state):
    """âœ… ä½¿ç”¨å¼‚æ­¥æ•°æ®åº“åŠ è½½è‡ªå®šä¹‰agent"""
    from app.db.async_session import AsyncSessionLocal
    from app.crud.async_crud_agent_profile import async_agent_profile
    
    agent_id = extract_agent_id_from_messages(state.get("messages", []))
    
    if agent_id:
        # âœ… å¼‚æ­¥æ•°æ®åº“ä¼šè¯
        async with AsyncSessionLocal() as db:
            # âœ… å¼‚æ­¥æŸ¥è¯¢ - ä¸é˜»å¡äº‹ä»¶å¾ªç¯
            profile = await async_agent_profile.get(db=db, id=agent_id)
            
            if profile and not profile.is_system:
                # âœ… å¼‚æ­¥åˆ›å»ºè‡ªå®šä¹‰agent
                custom_analyst = await create_custom_analyst_agent_async(
                    profile, 
                    db
                )
                
                self.supervisor_agent = create_intelligent_sql_supervisor(
                    custom_analyst=custom_analyst
                )
                
                logger.info(f"æˆåŠŸåŠ è½½è‡ªå®šä¹‰agent: {profile.name}")
    
    return state
```

---

### 3.3 æ€§èƒ½å¯¹æ¯”

**åœºæ™¯: 100ä¸ªå¹¶å‘è¯·æ±‚ï¼Œæ¯ä¸ªéœ€è¦æŸ¥è¯¢1æ¬¡æ•°æ®åº“**

| æ¨¡å¼ | æ•°æ®åº“æŸ¥è¯¢æ—¶é—´ | æ€»å“åº”æ—¶é—´ | QPS | å¤‡æ³¨ |
|------|-------------|-----------|-----|------|
| åŒæ­¥ORM | 50ms (é˜»å¡) | 8.5ç§’ | 12 | é˜»å¡äº‹ä»¶å¾ªç¯ |
| å¼‚æ­¥ORM | 50ms (éé˜»å¡) | 1.2ç§’ | 85 | å®Œå…¨å¼‚æ­¥ |

**æå‡: 7å€ååé‡**

---

## 4. è‡ªå®šä¹‰StreamWriterå®ç°

### 4.1 SQLæ‰§è¡Œè¿›åº¦æµå¼æ¨é€

```python
# backend/app/agents/agents/sql_executor_agent.py (å¢å¼º)

from langgraph.types import StreamWriter
from typing import Optional

async def sql_executor_node_streaming(
    state: SQLMessageState,
    writer: Optional[StreamWriter] = None
) -> SQLMessageState:
    """
    æ”¯æŒæµå¼è¿›åº¦æ¨é€çš„SQLæ‰§è¡ŒèŠ‚ç‚¹
    
    æ¨é€äº‹ä»¶:
    - validating: SQLéªŒè¯ä¸­
    - executing: æ‰§è¡ŒæŸ¥è¯¢ä¸­
    - formatting: æ ¼å¼åŒ–ç»“æœä¸­
    - completed: æ‰§è¡Œå®Œæˆ
    """
    
    # æ¨é€éªŒè¯é˜¶æ®µ
    if writer:
        writer({
            "type": "progress",
            "stage": "validating",
            "message": "æ­£åœ¨éªŒè¯SQLæŸ¥è¯¢..."
        })
    
    # éªŒè¯SQL
    sql = state.get("generated_sql", "")
    if not sql:
        raise ValueError("æœªæ‰¾åˆ°SQLæŸ¥è¯¢")
    
    # æ¨é€æ‰§è¡Œé˜¶æ®µ
    if writer:
        writer({
            "type": "progress",
            "stage": "executing",
            "message": "æ­£åœ¨æ‰§è¡ŒæŸ¥è¯¢...",
            "sql": sql
        })
    
    # æ‰§è¡ŒSQL
    connection_id = state.get("connection_id", 15)
    start_time = time.time()
    
    result = execute_sql_query.invoke({
        "sql_query": sql,
        "connection_id": connection_id,
        "timeout": 30
    })
    
    execution_time = time.time() - start_time
    
    # æ¨é€æ ¼å¼åŒ–é˜¶æ®µ
    if writer:
        writer({
            "type": "progress",
            "stage": "formatting",
            "message": "æ­£åœ¨æ ¼å¼åŒ–ç»“æœ...",
            "execution_time": execution_time
        })
    
    # æ ¼å¼åŒ–ç»“æœ
    if result.get("success"):
        data = result.get("data", [])
        
        execution_result = SQLExecutionResult(
            success=True,
            data=data,
            error=None,
            execution_time=execution_time,
            rows_affected=len(data)
        )
        
        # æ¨é€å®Œæˆäº‹ä»¶
        if writer:
            writer({
                "type": "progress",
                "stage": "completed",
                "message": f"æŸ¥è¯¢æˆåŠŸï¼Œè¿”å› {len(data)} æ¡è®°å½•",
                "row_count": len(data),
                "execution_time": execution_time
            })
        
        return {
            "execution_result": execution_result,
            "current_stage": "sql_execution_completed"
        }
    
    else:
        # é”™è¯¯æ¨é€
        if writer:
            writer({
                "type": "error",
                "stage": "failed",
                "message": "æŸ¥è¯¢æ‰§è¡Œå¤±è´¥",
                "error": result.get("error")
            })
        
        raise RuntimeError(f"SQLæ‰§è¡Œå¤±è´¥: {result.get('error')}")
```

---

### 4.2 å‰ç«¯å®æ—¶æ¥æ”¶è¿›åº¦

```typescript
// å‰ç«¯ç›‘å¬è‡ªå®šä¹‰äº‹ä»¶æµ

async function executeSQLWithProgress(query: string) {
  const eventSource = new EventSource('/api/query/chat/stream');
  
  eventSource.addEventListener('progress', (e) => {
    const progress = JSON.parse(e.data);
    
    switch (progress.stage) {
      case 'validating':
        showProgress('éªŒè¯SQL...', 10);
        break;
      
      case 'executing':
        showProgress('æ‰§è¡ŒæŸ¥è¯¢...', 40);
        showSQL(progress.sql);
        break;
      
      case 'formatting':
        showProgress('æ ¼å¼åŒ–ç»“æœ...', 80);
        showExecutionTime(progress.execution_time);
        break;
      
      case 'completed':
        showProgress('å®Œæˆ!', 100);
        showResults(progress.row_count);
        break;
    }
  });
}
```

---

## 5. æ‰¹å¤„ç†ä¼˜åŒ–

### 5.1 æ‰¹é‡æŸ¥è¯¢å¤„ç†

```python
# backend/app/api/api_v1/endpoints/query.py

@router.post("/chat/batch")
async def chat_query_batch(
    batch_request: schemas.BatchChatQueryRequest,
    db: Session = Depends(deps.get_db)
) -> schemas.BatchChatQueryResponse:
    """
    æ‰¹é‡æŸ¥è¯¢å¤„ç†
    
    ä¼˜åŠ¿:
    - å¹¶è¡Œæ‰§è¡Œå¤šä¸ªæŸ¥è¯¢
    - å…±äº«èµ„æºåˆå§‹åŒ–
    - æ‰¹é‡è¿”å›ç»“æœ
    """
    
    async def process_single_query(query_req: schemas.ChatQueryRequest):
        """å¤„ç†å•ä¸ªæŸ¥è¯¢"""
        try:
            graph = IntelligentSQLGraph()
            result = await graph.process_query(
                query=query_req.natural_language_query,
                connection_id=query_req.connection_id,
                thread_id=query_req.conversation_id
            )
            return {
                "success": True,
                "query_id": query_req.query_id,
                "result": result
            }
        except Exception as e:
            return {
                "success": False,
                "query_id": query_req.query_id,
                "error": str(e)
            }
    
    # å¹¶è¡Œå¤„ç†æ‰€æœ‰æŸ¥è¯¢
    tasks = [
        process_single_query(req) 
        for req in batch_request.queries
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    
    return schemas.BatchChatQueryResponse(
        results=results,
        total_queries=len(batch_request.queries),
        successful_queries=sum(1 for r in results if r.get("success"))
    )
```

---

### 5.2 æ€§èƒ½å¯¹æ¯”

**åœºæ™¯: å¤„ç†10ä¸ªæŸ¥è¯¢**

| æ¨¡å¼ | æ‰§è¡Œæ–¹å¼ | æ€»æ—¶é—´ | ååé‡ |
|------|---------|-------|--------|
| ä¸²è¡Œ | é€ä¸ªæ‰§è¡Œ | 150ç§’ (10 Ã— 15ç§’) | 0.07 QPS |
| æ‰¹é‡å¼‚æ­¥ | å¹¶è¡Œæ‰§è¡Œ | 18ç§’ (æœ€é•¿çš„æŸ¥è¯¢) | 0.56 QPS |

**æå‡: 8.3å€**

---

## 6. ç›‘æ§ä¸è°ƒè¯•å·¥å…·

### 6.1 å¼‚æ­¥ä»»åŠ¡æ€§èƒ½è¿½è¸ª

```python
# backend/app/core/async_monitor.py

import functools
import time
import asyncio
from typing import Callable, TypeVar, ParamSpec

P = ParamSpec('P')
T = TypeVar('T')

def async_performance_monitor(
    slow_threshold: float = 5.0
) -> Callable[[Callable[P, T]], Callable[P, T]]:
    """
    å¼‚æ­¥å‡½æ•°æ€§èƒ½ç›‘æ§è£…é¥°å™¨
    
    å‚æ•°:
        slow_threshold: æ…¢æŸ¥è¯¢é˜ˆå€¼(ç§’)
    """
    def decorator(func: Callable[P, T]) -> Callable[P, T]:
        @functools.wraps(func)
        async def wrapper(*args: P.args, **kwargs: P.kwargs) -> T:
            start_time = time.time()
            task_name = f"{func.__module__}.{func.__name__}"
            
            logger.debug(f"å¼€å§‹å¼‚æ­¥ä»»åŠ¡: {task_name}")
            
            try:
                result = await func(*args, **kwargs)
                duration = time.time() - start_time
                
                if duration > slow_threshold:
                    logger.warning(
                        f"æ…¢å¼‚æ­¥ä»»åŠ¡: {task_name} è€—æ—¶ {duration:.2f}ç§’"
                    )
                else:
                    logger.debug(
                        f"å®Œæˆå¼‚æ­¥ä»»åŠ¡: {task_name} è€—æ—¶ {duration:.2f}ç§’"
                    )
                
                # è®°å½•æŒ‡æ ‡
                async_task_duration.labels(
                    task_name=task_name,
                    status="success"
                ).observe(duration)
                
                return result
            
            except Exception as e:
                duration = time.time() - start_time
                logger.error(
                    f"å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {task_name} è€—æ—¶ {duration:.2f}ç§’, é”™è¯¯: {e}"
                )
                
                async_task_duration.labels(
                    task_name=task_name,
                    status="error"
                ).observe(duration)
                
                raise
        
        return wrapper
    return decorator

# ä½¿ç”¨ç¤ºä¾‹
@async_performance_monitor(slow_threshold=3.0)
async def cache_check_node(state: SQLMessageState):
    # ...
    pass
```

---

### 6.2 å¼‚æ­¥å¹¶å‘é™æµ

```python
# backend/app/core/async_limiter.py

import asyncio
from typing import Callable, TypeVar

T = TypeVar('T')

class AsyncLimiter:
    """
    å¼‚æ­¥å¹¶å‘é™æµå™¨
    
    é˜²æ­¢è¿‡å¤šå¹¶å‘ä»»åŠ¡è€—å°½èµ„æº
    """
    
    def __init__(self, max_concurrent: int = 100):
        self.semaphore = asyncio.Semaphore(max_concurrent)
    
    async def __aenter__(self):
        await self.semaphore.acquire()
        return self
    
    async def __aexit__(self, exc_type, exc_val, exc_tb):
        self.semaphore.release()
    
    async def run(self, coro: Callable[[], T]) -> T:
        """è¿è¡Œå—é™çš„åç¨‹"""
        async with self:
            return await coro()

# å…¨å±€é™æµå™¨
query_limiter = AsyncLimiter(max_concurrent=100)

# ä½¿ç”¨ç¤ºä¾‹
async def process_query_with_limit(query: str):
    async with query_limiter:
        result = await graph.process_query(query)
        return result
```

---

## 7. æ€»ç»“

ä»¥ä¸Šä¼˜åŒ–æ–¹æ¡ˆæŒ‰ä¼˜å…ˆçº§å®æ–½:

| ä¼˜å…ˆçº§ | ä¼˜åŒ–æ–¹æ¡ˆ | å®æ–½éš¾åº¦ | æ€§èƒ½æå‡ | ç”¨æˆ·ä½“éªŒæå‡ |
|-------|---------|---------|---------|------------|
| ğŸ”´ é«˜ | æµå¼å“åº”API | ä¸­ | +30% | â­â­â­â­â­ |
| ğŸ”´ é«˜ | å¹¶è¡Œç¼“å­˜æ£€æŸ¥ | ä½ | +25% | â­â­â­â­ |
| ğŸŸ¡ ä¸­ | å¼‚æ­¥ORMè¿ç§» | é«˜ | +40% | â­â­â­ |
| ğŸŸ¡ ä¸­ | è‡ªå®šä¹‰StreamWriter | ä¸­ | +20% | â­â­â­â­â­ |
| ğŸŸ¢ ä½ | æ‰¹å¤„ç†ä¼˜åŒ– | ä½ | +50% | â­â­â­ |

**å»ºè®®å®æ–½é¡ºåº:**
1. å¹¶è¡Œç¼“å­˜æ£€æŸ¥ (Week 1)
2. æµå¼å“åº”API (Week 2-3)
3. è‡ªå®šä¹‰StreamWriter (Week 4)
4. æ‰¹å¤„ç†ä¼˜åŒ– (Week 5)
5. å¼‚æ­¥ORMè¿ç§» (Week 6-8)

---

**æ–‡æ¡£ç‰ˆæœ¬**: v1.0  
**æœ€åæ›´æ–°**: 2026-01-20
